{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LRQ79Wuxkd7l",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fa16695d-ce01-4ca6-e6e8-e20c1f255c01"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from google.colab import drive\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "paths = []\n",
    "\n",
    "drive.mount('/content/gdrive/', force_remount=False)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "      img = tf.keras.utils.load_img(os.path.join(folder,filename), target_size=(224, 224))\n",
    "      if img is not None:\n",
    "        paths.append(os.path.join(folder,filename))\n",
    "        images.append(img)\n",
    "    return images"
   ],
   "metadata": {
    "id": "V4fUTAfdtZ1V"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## VGG16 Model\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "base_model.trainable =  False\n",
    "\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "output = keras.layers.GlobalAveragePooling2D()(x)\n",
    "model = keras.Model(inputs, output)"
   ],
   "metadata": {
    "id": "Db4Cj1ys3AxV"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_feature_vector(image):\n",
    "  x = tf.keras.utils.img_to_array(image)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  return model.predict(x)\n",
    "\n",
    "def images2features(images):\n",
    "  features = []\n",
    "  for image in images:\n",
    "    features.append(get_feature_vector(image)[0])\n",
    "  return features"
   ],
   "metadata": {
    "id": "uJ02-j8OX0vf"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(features):\n",
    "  kmeans_model = KMeans(n_clusters=2, random_state=0).fit(features)\n",
    "  return kmeans_model"
   ],
   "metadata": {
    "id": "Hv2QZ_cXwzrK"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Read images for Kmeans\n",
    "images1 = load_images_from_folder(\"/content/gdrive/MyDrive/Colab Notebooks/Dataset/Clouds and Lines/ba_202201/\")\n",
    "images2 = load_images_from_folder(\"/content/gdrive/MyDrive/Colab Notebooks/Dataset/Clouds and Lines/pm_20220125/\")\n",
    "images3 = load_images_from_folder(\"/content/gdrive/MyDrive/Colab Notebooks/Dataset/Clouds and Lines/pm_20220226/\")\n",
    "images4 = load_images_from_folder(\"/content/gdrive/MyDrive/Colab Notebooks/Dataset/Clouds and Lines/va_20220213/\")\n",
    "\n",
    "# Combine all lists\n",
    "images = images1 + images2 + images3 + images4\n",
    "\n",
    "# Extract features from the images\n",
    "features = images2features(images)\n",
    "# Train Kmeans model\n",
    "kmeans_model = train(features)"
   ],
   "metadata": {
    "id": "rfUrzRYKto9K"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Predict output of same images using trained model\n",
    "output_clusters = kmeans_model.predict(features)"
   ],
   "metadata": {
    "id": "k0xHih20-Hfx"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "\n",
    "i = 0\n",
    "for output in output_clusters:\n",
    "  if output == 0:\n",
    "    # save in cluster 0\n",
    "    shutil.copy(paths[i], \"/content/gdrive/MyDrive/Colab Notebooks/Dataset/Output/cluster0/\")\n",
    "  else:\n",
    "    # save in cluster 1\n",
    "    shutil.copy(paths[i], \"/content/gdrive/MyDrive/Colab Notebooks/Dataset/Output/cluster1/\")\n",
    "  i = i+1"
   ],
   "metadata": {
    "id": "k7xB00eR-Hkn"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(kmeans_model, f)"
   ],
   "metadata": {
    "id": "vfzWrGvEDajd"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "WlMuci4FeRmK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "kHdm60yAeRpn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Predict Function\n",
    "\n",
    "# Load pickel model\n",
    "with open(\"model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "def predict(image):\n",
    "  feature_vec = get_feature_vector(image)[0]\n",
    "  result = kmeans_model.predict([feature_vec])\n",
    "  return result"
   ],
   "metadata": {
    "id": "srQUOxn6-Hm8"
   },
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tt_ABJzz-HqY"
   },
   "execution_count": 64,
   "outputs": []
  }
 ]
}
